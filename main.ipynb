{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94d66d5afecedecc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:12.408209Z",
     "start_time": "2024-12-06T07:24:12.387365600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import PIL\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, RandomHorizontalFlip\n",
    "from torchvision.datasets import ImageFolder\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "from model import CNNModel\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-mode MODE] [-num_epoches NUM_EPOCHES]\n",
      "                             [-fc_hidden1 FC_HIDDEN1] [-fc_hidden2 FC_HIDDEN2]\n",
      "                             [-learning_rate LEARNING_RATE] [-decay DECAY]\n",
      "                             [-batch_size BATCH_SIZE] [-dropout DROPOUT]\n",
      "                             [-rotation ROTATION] [-activation ACTIVATION]\n",
      "                             [-channel_out1 CHANNEL_OUT1]\n",
      "                             [-channel_out2 CHANNEL_OUT2] [-k_size K_SIZE]\n",
      "                             [-pooling_size POOLING_SIZE] [-stride STRIDE]\n",
      "                             [-max_stride MAX_STRIDE] [-ckp_path CKP_PATH]\n",
      "ipykernel_launcher.py: error: ambiguous option: -f could match -fc_hidden1, -fc_hidden2\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\u001B[1;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "## input hyper-paras\n",
    "parser = argparse.ArgumentParser(description=\"nueral networks\")\n",
    "parser.add_argument(\"-mode\", dest=\"mode\", type=str, default='train', help=\"train or test\")\n",
    "parser.add_argument(\"-num_epoches\", dest=\"num_epoches\", type=int, default=40, help=\"num of epoches\")\n",
    "\n",
    "parser.add_argument(\"-fc_hidden1\", dest=\"fc_hidden1\", type=int, default=50, help=\"dim of hidden neurons\")\n",
    "parser.add_argument(\"-fc_hidden2\", dest=\"fc_hidden2\", type=int, default=50, help=\"dim of hidden neurons\")\n",
    "parser.add_argument(\"-learning_rate\", dest=\"learning_rate\", type=float, default=0.0001, help=\"learning rate\")\n",
    "parser.add_argument(\"-decay\", dest=\"decay\", type=float, default=0.01, help=\"learning rate\")\n",
    "parser.add_argument(\"-batch_size\", dest=\"batch_size\", type=int, default=100, help=\"batch size\")\n",
    "parser.add_argument(\"-dropout\", dest=\"dropout\", type=float, default=0.4, help=\"dropout prob\")\n",
    "parser.add_argument(\"-rotation\", dest=\"rotation\", type=int, default=10, help=\"image rotation\")\n",
    "parser.add_argument(\"-activation\", dest=\"activation\", type=str, default='relu', help=\"activation function\")\n",
    "parser.add_argument(\"-channel_out1\", dest='channel_out1', type=int, default=64, help=\"number of channels\")\n",
    "parser.add_argument(\"-channel_out2\", dest='channel_out2', type=int, default=64, help=\"number of channels\")\n",
    "parser.add_argument(\"-k_size\", dest='k_size', type=int, default=5, help=\"size of filter\")\n",
    "parser.add_argument(\"-pooling_size\", dest='pooling_size', type=int, default=2, help=\"size for max pooling\")\n",
    "parser.add_argument(\"-stride\", dest='stride', type=int, default=1, help=\"stride for filter\")\n",
    "parser.add_argument(\"-max_stride\", dest='max_stride', type=int, default=2, help=\"stride for max pooling\")\n",
    "parser.add_argument(\"-ckp_path\", dest='ckp_path', type=str, default=\"checkpoint\", help=\"path of checkpoint\")\n",
    "\n",
    "args = parser.parse_args()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:12.427019600Z",
     "start_time": "2024-12-06T07:24:12.399127100Z"
    }
   },
   "id": "84caadb3eb926ea",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define a series of transformations for the training data.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),  # Resize the images to 150x150 pixels.\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Randomly flip the images horizontally 50% of the time.\n",
    "    transforms.RandomAffine(  # Apply random affine transformations to the images.\n",
    "        degrees=(-5, 5),  # Rotate by degrees between -5 and 5.\n",
    "        translate=(0.1, 0.1),  # Translate by a fraction of image width/height (10% here).\n",
    "        scale=(0.9, 1.1),  # Scale images between 90% and 110%.\n",
    "        # resample=PIL.Image.BILINEAR  # Use bilinear interpolation for resampling.\n",
    "        interpolation=PIL.Image.BILINEAR  # Use 'interpolation' instead of 'resample'\n",
    "    ),\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors.\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize tensors with mean and standard deviation.\n",
    "])\n",
    "\n",
    "# Define transformations for the test data.\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors.\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize tensors with mean and standard deviation.\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:12.429240Z",
     "start_time": "2024-12-06T07:24:12.413589800Z"
    }
   },
   "id": "6e3dd62c4916b960",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data_dir, batch_size, train_val_split=0.8):\n",
    "\n",
    "    # Define the data transformations\n",
    "    train_transform = Compose([\n",
    "        Resize((64, 64)),\n",
    "        RandomHorizontalFlip(p=0.5),  # Augmentation for training\n",
    "        ToTensor()\n",
    "    ])\n",
    "    test_transform = Compose([\n",
    "        Resize((64, 64)),\n",
    "        ToTensor()\n",
    "    ])\n",
    "\n",
    "    # Paths for train and test data\n",
    "    train_path = os.path.join(data_dir, 'asl_alphabet_train', 'asl_alphabet_train')\n",
    "    test_path = os.path.join(data_dir, 'asl_alphabet_test', 'asl_alphabet_test')\n",
    "\n",
    "    # Load the training dataset\n",
    "    train_dataset = ImageFolder(root=train_path, transform=train_transform)\n",
    "\n",
    "    # Split the training dataset into training and validation sets\n",
    "    dataset_size = len(train_dataset)\n",
    "    train_size = int(dataset_size * train_val_split)\n",
    "    val_size = dataset_size - train_size\n",
    "    train_set, val_set = random_split(\n",
    "        train_dataset,\n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)  # Ensure reproducibility\n",
    "    )\n",
    "\n",
    "    # Create the data loaders\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # Load the test dataset\n",
    "    if not os.path.exists(test_path):\n",
    "        raise FileNotFoundError(f\"Test directory {test_path} does not exist.\")\n",
    "    test_set = ImageFolder(root=test_path, transform=test_transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader, test_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:12.507981300Z",
     "start_time": "2024-12-06T07:24:12.436757600Z"
    }
   },
   "id": "4c39c13834efb34c",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_batch):\n",
    "    accy = (y_pred == y_batch).sum().item() / y_batch.size(0)\n",
    "    return accy\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:12.509054400Z",
     "start_time": "2024-12-06T07:24:12.441540Z"
    }
   },
   "id": "63455698d122c9e2",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33masully88865\u001B[0m (\u001B[33marsullivan\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.19.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.5"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Users\\asull\\PycharmProjects\\CSCI416-FinalProject\\wandb\\run-20241206_022415-nkwrji4p</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/arsullivan/ASL/runs/nkwrji4p/workspace' target=\"_blank\">ASL Project</a></strong> to <a href='https://wandb.ai/arsullivan/ASL' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/arsullivan/ASL' target=\"_blank\">https://wandb.ai/arsullivan/ASL</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/arsullivan/ASL/runs/nkwrji4p/workspace' target=\"_blank\">https://wandb.ai/arsullivan/ASL/runs/nkwrji4p/workspace</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.009 MB of 0.035 MB uploaded\\r'), FloatProgress(value=0.2564911231342269, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba49ae0e80c84c0a8a81fb86243babae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">ASL Project</strong> at: <a href='https://wandb.ai/arsullivan/ASL/runs/nkwrji4p/workspace' target=\"_blank\">https://wandb.ai/arsullivan/ASL/runs/nkwrji4p/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20241206_022415-nkwrji4p\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "  with wandb.init(project='ASL', name='ASL Project'):\n",
    "        time_start = time.time()\n",
    "   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:36.231874900Z",
     "start_time": "2024-12-06T07:24:12.458813100Z"
    }
   },
   "id": "6a57a3456cd832d4",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m use_cuda \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available()\n\u001B[0;32m      3\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_cuda \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mset_device(device\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice: \u001B[39m\u001B[38;5;124m\"\u001B[39m, device)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:408\u001B[0m, in \u001B[0;36mset_device\u001B[1;34m(device)\u001B[0m\n\u001B[0;32m    406\u001B[0m device \u001B[38;5;241m=\u001B[39m _get_device_index(device)\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 408\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_cuda_setDevice(device)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "        # get the device\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        torch.cuda.set_device(device=0)\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"device: \", device)\n",
    "        if use_cuda:\n",
    "            torch.cuda.manual_seed(72)\n",
    "    \n",
    "        train_loader, test_loader, test_set = load_data('./asl-alphabet/versions/1', args.batch_size)\n",
    "    \n",
    "        # Your training code here\n",
    "        model = CNNModel(args)\n",
    "    \n",
    "        ## load model to gpu or cpu\n",
    "        model.to(device)\n",
    "    \n",
    "        ## initialize hyper-parameters\n",
    "        num_epoches = args.num_epoches\n",
    "        learning_rate = args.learning_rate\n",
    "    \n",
    "        ## define criterion, optimizer, and scheduler\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0,\n",
    "                               amsgrad=False)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, min_lr=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:36.796077500Z",
     "start_time": "2024-12-06T07:24:36.236167900Z"
    }
   },
   "id": "c85605c153a38c0b",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "      # Get data loaders\n",
    "        if args.mode == 'train':\n",
    "            model.train()\n",
    "    \n",
    "            for epoch in range(num_epoches):\n",
    "                print(f\"\\nEpoch {epoch}/{num_epoches}\")\n",
    "                print(\"-\" * 20)\n",
    "    \n",
    "                epoch_loss = 0.0\n",
    "                epoch_correct = 0\n",
    "                epoch_total = 0\n",
    "    \n",
    "                for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "                    # Move to device\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "    \n",
    "                    # Forward pass\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "    \n",
    "                    # Backward pass and optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "    \n",
    "                    # Compute accuracy\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    epoch_total += labels.size(0)\n",
    "                    epoch_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "                    # Batch-level logging\n",
    "                    batch_acc = (predicted == labels).float().mean().item()\n",
    "                    print(f\"Batch {batch_idx}: Loss = {loss.item():.4f}, Batch Accuracy = {batch_acc:.4f}\")\n",
    "    \n",
    "                    # Accumulate epoch loss\n",
    "                    epoch_loss += loss.item()\n",
    "    \n",
    "                # Epoch-level metrics\n",
    "                epoch_loss /= len(train_loader)\n",
    "                epoch_accuracy = epoch_correct / epoch_total\n",
    "    \n",
    "                print(f\"Epoch {epoch} Summary:\")\n",
    "                print(f\"  Average Loss: {epoch_loss:.4f}\")\n",
    "                print(f\"  Epoch Accuracy: {epoch_accuracy:.4f}\")\n",
    "    \n",
    "                # WandB logging\n",
    "                wandb.log({\n",
    "                    'epoch': epoch,\n",
    "                    'loss': epoch_loss,\n",
    "                    'accuracy': epoch_accuracy\n",
    "                })\n",
    "    \n",
    "                # Learning rate scheduling\n",
    "                scheduler.step(epoch_loss)\n",
    "                \n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-06T07:24:36.817563800Z",
     "start_time": "2024-12-06T07:24:36.800573500Z"
    }
   },
   "id": "e5404867dc201a72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "        test_acc = 0.0\n",
    "    \n",
    "        model.eval()\n",
    "        pred_vec = []\n",
    "        correct = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                x_batch, y_labels = data\n",
    "                x_batch, y_labels = x_batch.to(device), y_labels.to(device)\n",
    "    \n",
    "                output_y = model(x_batch)\n",
    "                _, predicted = torch.max(output_y, 1)\n",
    "    \n",
    "                correct += (predicted == y_labels).sum().item()\n",
    "                pred_vec.append(predicted)\n",
    "            pred_vec = torch.cat(pred_vec)\n",
    "    \n",
    "        print(\"test accuracy: \", test_acc / len(test_loader))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-06T07:24:36.802710700Z"
    }
   },
   "id": "b5406c817304993a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "        # visualize wrongly classified image for each class\n",
    "        pred_vec = pred_vec.cpu().numpy()\n",
    "        ground_truths = np.asarray(test_set.targets)\n",
    "        incorrect_mask = pred_vec != ground_truths\n",
    "        incorrect_images = [test_set.data[(ground_truths == label) & incorrect_mask][0] for label in range(10)]\n",
    "        pred_results = [pred_vec[(ground_truths == label) & incorrect_mask][0] for label in range(10)]\n",
    "    \n",
    "        # show images\n",
    "        classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "    \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "        i = 0\n",
    "        for row in axes:\n",
    "            for axis in row:\n",
    "                axis.set_xticks([])\n",
    "                axis.set_yticks([])\n",
    "                axis.set_xlabel(\"Predicted: %s\" % classes[pred_results[i]], fontsize=14)\n",
    "                axis.imshow(incorrect_images[i])\n",
    "                i += 1\n",
    "                \n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-06T07:24:36.803797800Z"
    }
   },
   "id": "211de496ae7be0cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "        time_end = time.time()\n",
    "        print(\"running time: \", (time_end - time_start) / 60.0, \"mins\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-12-06T07:24:36.804869400Z"
    }
   },
   "id": "initial_id",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
